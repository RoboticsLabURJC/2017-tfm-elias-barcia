\chapter{Conclusiones} \label{cap:conclusiones}
La robótica móvil es ya una realidad gracias a los algoritmos Visual SLAM que permiten estimar con mínimo error la localización y generación de mapas en entornos desconocidos.
En este documento se han descrito algunos de estos algoritmos que ya están funcionando, pero se sigue investigando en la generación de nuevos métodos de navegación autónoma para conseguir mayor fiabilidad , robusted y exactitud de los cálculos.
Dependiendo de las características del entorno o de los requisitos del problema que estemos tratando será más conveniente utilizar un algoritmo u otro. Por ejemplo, si necesitásemos generar un mapa de grán exactitud, lo más conveniente sería utilizar DTAM, si por el contrario el mapa no fuese muy importante y la potencia del hardware fuese muy limitada podríamos utilizar SVO.

Por ahora las limitaciones hardware hacen que en robótica móvil se opte por utilizar aquellas técnicas que requieren poca capacidad de cómputo (PTAM,SVO,MonoSLAM) ya que son facilmente procesables por los micropocesadores de los actuales robots móviles. En el futuro y a medida que los robots tengan más capacidad de proceso , probablemente se impongan los métodos más robustos que realicen una localización más exacta y cuyos mapas sean muy fiables como podría ser el método ORB-SLAM o DSO.

No obstante todavía queda un camino largo que avanzar en Visual SLAM, ya que algunos algoritmos no son del todo robustos en grandes espacios o entornos donde exista excesivo movimiento alrededor de la cámara, por ejemplo si nuestro robot se encontrase en un jardín frondoso , donde soplase una cierta brisa, le sería dificil al robot mapear el entorno ya que el movimiento de hojas y ramas podría generar inestabilidad en la estimación de la posición 3D de la cámara.

Aunque la gran revolución se producirá cuando la mayoría de smartphones y cámaras estén equipadas con dispositivos que puedan medir la profundidad de las imágenes, como el proyecto Tango. Sin duda los cálculos de mapeo y posición se acelerarán y mejorará notablemente la exactitud de las estimaciones de posición. No sería de extrañar que apareciesen nuevos dispositivos periféricos que podrian ser controlados por el smartphone, por ejemplo un nuevo tipo de aspiradora , sin ningun tipo de capacidad para realizar Visual SLAM, solo un par de motores que le permitan avanzar y girar. Si quisiesemos que esta asapiradora comenzase a aspirar de forma autónoma sólo tendríamos que colocar nuestro smartphone de forma vertical sobre ella. El smartphone comenzaría a mapear la habitación y a dirigir la navegación de la aspiradora hasta que todo el suelo de la habitación quedase límpio. De esta forma todo el proceso de Visual SLAM de la aspiradora quedaría relegada al smartphone. Y quien sabe, quizá el futuro de la conducción autónoma dependa del software de Visual SLAM con el que esten equipados los cada vez más potentes SmartPhones.
